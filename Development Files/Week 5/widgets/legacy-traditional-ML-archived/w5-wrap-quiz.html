<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Week 5 Wrap-up Quiz - AMBA Template</title>
  <!-- Canvas iframe sizing hint -->
  <meta name="canvas-height" content="900">
  <meta name="description" content="Comprehensive 8-question quiz on deployment and governance with explanations">
  <link rel="stylesheet" href="ivey-widget-base.css">
  <style>
    * { box-sizing: border-box; margin: 0; padding: 0; }
    body { font-family: Arial, sans-serif; background: white; color: #333; line-height: 1.5; }
    .dp-wrapper { max-width: 800px; margin: 0 auto; padding: 15px; background: #ffffff; }
    .widget-header { background: #034638; color: white; padding: 12px 16px; text-align: center; border-radius: 8px 8px 0 0; margin: -15px -15px 20px -15px; }
    .widget-title { font-size: 1.2em; font-weight: bold; margin: 0; }
    .quiz-container { background: #f8f9fa; border: 2px solid #034638; border-radius: 8px; padding: 20px; margin: 15px 0; }
    .question-card { background: white; border: 1px solid #ddd; border-radius: 8px; padding: 20px; margin: 15px 0; }
    .question-header { display: flex; justify-content: space-between; align-items: center; margin-bottom: 15px; }
    .question-number { background: #034638; color: white; padding: 6px 12px; border-radius: 20px; font-weight: bold; font-size: 0.9em; }
    .question-score { color: #666; font-size: 0.9em; }
    .question-text { font-size: 1.1em; font-weight: bold; margin-bottom: 15px; color: #034638; }
    .options-container { margin: 15px 0; }
    .option { background: #f8f9fa; border: 2px solid #e9ecef; border-radius: 6px; padding: 12px; margin: 8px 0; cursor: pointer; transition: all 0.2s ease; display: flex; align-items: center; gap: 10px; }
    .option:hover { border-color: #034638; background: #e8f5e8; }
    .option.selected { border-color: #034638; background: #e8f5e8; }
    .option.correct { border-color: #198754; background: #d1e7dd; }
    .option.incorrect { border-color: #dc3545; background: #f8d7da; }
    .option-marker { width: 20px; height: 20px; border: 2px solid #ccc; border-radius: 50%; display: flex; align-items: center; justify-content: center; font-weight: bold; }
    .option.selected .option-marker { border-color: #034638; background: #034638; color: white; }
    .option.correct .option-marker { border-color: #198754; background: #198754; color: white; }
    .option.incorrect .option-marker { border-color: #dc3545; background: #dc3545; color: white; }
    .explanation { background: #e8f5e8; border-left: 4px solid #198754; padding: 12px; margin: 15px 0; border-radius: 0 4px 4px 0; display: none; }
    .explanation.show { display: block; }
    .explanation-title { font-weight: bold; color: #034638; margin-bottom: 8px; }
    .controls { text-align: center; margin: 20px 0; }
    .btn { background: #034638; color: white; border: none; padding: 10px 20px; border-radius: 4px; cursor: pointer; font-size: 14px; margin: 5px; }
    .btn:hover { background: #045a42; }
    .btn:disabled { background: #6c757d; cursor: not-allowed; }
    .btn-check { background: #582C83; }
    .btn-check:hover { background: #6d3499; }
    .progress-container { background: white; border: 2px solid #034638; border-radius: 8px; padding: 15px; margin: 15px 0; }
    .progress-title { color: #034638; font-weight: bold; margin-bottom: 10px; }
    .progress-bar { background: #e9ecef; border-radius: 10px; height: 25px; overflow: hidden; margin: 10px 0; }
    .progress-fill { background: var(--ivey-green); height: 100%; transition: width 0.3s ease; display: flex; align-items: center; justify-content: center; color: white; font-weight: bold; font-size: 0.9em; }
    .stats-grid { display: grid; grid-template-columns: repeat(3, 1fr); gap: 15px; margin: 15px 0; }
    .stat-card { background: #f8f9fa; border: 1px solid #ddd; border-radius: 6px; padding: 12px; text-align: center; }
    .stat-value { font-size: 1.5em; font-weight: bold; color: #034638; }
    .stat-label { font-size: 0.9em; color: #666; }
    .results-panel { background: #e8f5e8; border: 2px solid #198754; border-radius: 8px; padding: 20px; margin: 20px 0; text-align: center; display: none; }
    .results-panel.show { display: block; }
    .results-title { color: #034638; font-size: 1.3em; font-weight: bold; margin-bottom: 15px; }
    .final-score { font-size: 2em; font-weight: bold; color: #198754; margin: 10px 0; }
    .performance-message { font-size: 1.1em; margin: 15px 0; }
    .badge { display: inline-block; background: #034638; color: white; padding: 6px 12px; border-radius: 20px; font-size: 0.9em; margin: 5px; }
    .badge.excellent { background: #198754; }
    .badge.good { background: #582C83; }
    .badge.needs-improvement { background: #ffc107; color: #1a202c; }
  </style>
</head>
<body>
  <!-- Pop-out button -->
  <button class="widget-popout-btn" id="popoutBtn" title="Open in full window">
    <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor">
      <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2"
            d="M10 6H6a2 2 0 00-2 2v10a2 2 0 002 2h10a2 2 0 002-2v-4M14 4h6m0 0v6m0-6L10 14" />
    </svg>
    <span>Pop Out</span>
  </button>

<div class="dp-wrapper">
  <div class="widget-header">
    <h1 class="widget-title">Week 5: Deployment & Governance - Knowledge Check</h1>
  </div>

  <div class="quiz-container">
    <div class="progress-container">
      <div class="progress-title">Quiz Progress</div>
      <div class="progress-bar">
        <div class="progress-fill" id="progress-fill" style="width: 0%">0 / 8</div>
      </div>
      <div class="stats-grid">
        <div class="stat-card">
          <div class="stat-value" id="answered-count">0</div>
          <div class="stat-label">Answered</div>
        </div>
        <div class="stat-card">
          <div class="stat-value" id="correct-count">0</div>
          <div class="stat-label">Correct</div>
        </div>
        <div class="stat-card">
          <div class="stat-value" id="score-percent">0%</div>
          <div class="stat-label">Score</div>
        </div>
      </div>
    </div>

    <!-- Question 1 -->
    <div class="question-card">
      <div class="question-header">
        <span class="question-number">Question 1</span>
        <span class="question-score">10 points</span>
      </div>
      <div class="question-text">What is the primary purpose of a "canary deployment" in ML model rollouts?</div>
      <div class="options-container">
        <div class="option" onclick="selectOption(1, 1, false)">
          <div class="option-marker">A</div>
          <div>To test model performance on historical data before deployment</div>
        </div>
        <div class="option" onclick="selectOption(1, 2, true)">
          <div class="option-marker">B</div>
          <div>To gradually expose a new model to a small subset of live traffic to monitor for issues</div>
        </div>
        <div class="option" onclick="selectOption(1, 3, false)">
          <div class="option-marker">C</div>
          <div>To compare multiple model versions simultaneously in production</div>
        </div>
        <div class="option" onclick="selectOption(1, 4, false)">
          <div class="option-marker">D</div>
          <div>To automatically rollback a model when performance degrades</div>
        </div>
      </div>
      <div class="explanation" id="explanation-1">
        <div class="explanation-title">Explanation:</div>
        A canary deployment gradually routes a small percentage of traffic to a new model version while monitoring for issues. This allows teams to detect problems early with minimal impact before full deployment. The term comes from "canary in a coal mine" - using a small signal to detect danger.
      </div>
    </div>

    <!-- Question 2 -->
    <div class="question-card">
      <div class="question-header">
        <span class="question-number">Question 2</span>
        <span class="question-score">10 points</span>
      </div>
      <div class="question-text">Which metric is most commonly used to detect data drift in production ML systems?</div>
      <div class="options-container">
        <div class="option" onclick="selectOption(2, 1, false)">
          <div class="option-marker">A</div>
          <div>Model accuracy degradation over time</div>
        </div>
        <div class="option" onclick="selectOption(2, 2, true)">
          <div class="option-marker">B</div>
          <div>Population Stability Index (PSI) comparing feature distributions</div>
        </div>
        <div class="option" onclick="selectOption(2, 3, false)">
          <div class="option-marker">C</div>
          <div>Prediction latency increase</div>
        </div>
        <div class="option" onclick="selectOption(2, 4, false)">
          <div class="option-marker">D</div>
          <div>Number of prediction requests per day</div>
        </div>
      </div>
      <div class="explanation" id="explanation-2">
        <div class="explanation-title">Explanation:</div>
        Population Stability Index (PSI) measures how much a feature's distribution has shifted between reference and current periods. PSI > 0.25 typically indicates significant drift requiring investigation. While accuracy degradation can indicate drift, PSI proactively detects distribution changes before they affect performance.
      </div>
    </div>

    <!-- Question 3 -->
    <div class="question-card">
      <div class="question-header">
        <span class="question-number">Question 3</span>
        <span class="question-score">10 points</span>
      </div>
      <div class="question-text">In ML model governance, what is the primary purpose of a "model card"?</div>
      <div class="options-container">
        <div class="option" onclick="selectOption(3, 1, false)">
          <div class="option-marker">A</div>
          <div>To store model weights and parameters for deployment</div>
        </div>
        <div class="option" onclick="selectOption(3, 2, false)">
          <div class="option-marker">C</div>
          <div>To automatically monitor model performance in production</div>
        </div>
        <div class="option" onclick="selectOption(3, 3, true)">
          <div class="option-marker">B</div>
          <div>To document model behavior, limitations, and intended use cases</div>
        </div>
        <div class="option" onclick="selectOption(3, 4, false)">
          <div class="option-marker">D</div>
          <div>To version control training data and feature engineering steps</div>
        </div>
      </div>
      <div class="explanation" id="explanation-3">
        <div class="explanation-title">Explanation:</div>
        Model cards provide transparency about model capabilities, limitations, performance across different groups, and intended use cases. They help stakeholders understand when and how to use a model appropriately, supporting responsible AI practices and regulatory compliance.
      </div>
    </div>

    <!-- Question 4 -->
    <div class="question-card">
      <div class="question-header">
        <span class="question-number">Question 4</span>
        <span class="question-score">10 points</span>
      </div>
      <div class="question-text">What is the key difference between shadow mode and A/B testing for model deployment?</div>
      <div class="options-container">
        <div class="option" onclick="selectOption(4, 1, true)">
          <div class="option-marker">A</div>
          <div>Shadow mode runs the new model without affecting user experience, while A/B testing shows different results to different users</div>
        </div>
        <div class="option" onclick="selectOption(4, 2, false)">
          <div class="option-marker">B</div>
          <div>Shadow mode is used for batch predictions, while A/B testing is for real-time inference</div>
        </div>
        <div class="option" onclick="selectOption(4, 3, false)">
          <div class="option-marker">C</div>
          <div>Shadow mode compares multiple models, while A/B testing uses only one model</div>
        </div>
        <div class="option" onclick="selectOption(4, 4, false)">
          <div class="option-marker">D</div>
          <div>Shadow mode requires more computational resources than A/B testing</div>
        </div>
      </div>
      <div class="explanation" id="explanation-4">
        <div class="explanation-title">Explanation:</div>
        In shadow mode, the new model runs in parallel with the current model but its predictions aren't shown to users - it's purely for comparison and monitoring. A/B testing actually serves different model predictions to different user groups to measure real-world performance differences.
      </div>
    </div>

    <!-- Question 5 -->
    <div class="question-card">
      <div class="question-header">
        <span class="question-number">Question 5</span>
        <span class="question-score">15 points</span>
      </div>
      <div class="question-text">Which scenario would most likely require immediate model rollback in a production fraud detection system?</div>
      <div class="options-container">
        <div class="option" onclick="selectOption(5, 1, false)">
          <div class="option-marker">A</div>
          <div>Prediction latency increases from 50ms to 75ms</div>
        </div>
        <div class="option" onclick="selectOption(5, 2, true)">
          <div class="option-marker">B</div>
          <div>False positive rate suddenly jumps from 2% to 15%, blocking legitimate transactions</div>
        </div>
        <div class="option" onclick="selectOption(5, 3, false)">
          <div class="option-marker">C</div>
          <div>Model confidence scores show slightly higher uncertainty than usual</div>
        </div>
        <div class="option" onclick="selectOption(5, 4, false)">
          <div class="option-marker">D</div>
          <div>Daily prediction volume decreases by 10%</div>
        </div>
      </div>
      <div class="explanation" id="explanation-5">
        <div class="explanation-title">Explanation:</div>
        A sudden increase in false positives from 2% to 15% means the model is incorrectly flagging 7.5x more legitimate transactions as fraud, severely impacting customer experience and business revenue. This requires immediate rollback. The other scenarios warrant investigation but aren't immediately critical.
      </div>
    </div>

    <!-- Question 6 -->
    <div class="question-card">
      <div class="question-header">
        <span class="question-number">Question 6</span>
        <span class="question-score">15 points</span>
      </div>
      <div class="question-text">What is the primary challenge of the "last-mile gap" in ML deployment?</div>
      <div class="options-container">
        <div class="option" onclick="selectOption(6, 1, false)">
          <div class="option-marker">A</div>
          <div>Models that work in notebooks don't scale to large datasets</div>
        </div>
        <div class="option" onclick="selectOption(6, 2, false)">
          <div class="option-marker">B</div>
          <div>Training takes too long on production hardware</div>
        </div>
        <div class="option" onclick="selectOption(6, 3, true)">
          <div class="option-marker">C</div>
          <div>Technical and organizational barriers prevent working models from delivering business value</div>
        </div>
        <div class="option" onclick="selectOption(6, 4, false)">
          <div class="option-marker">D</div>
          <div>Model accuracy degrades when moving from development to production</div>
        </div>
      </div>
      <div class="explanation" id="explanation-6">
        <div class="explanation-title">Explanation:</div>
        The "last-mile gap" refers to the disconnect between a working model in development and actual business value delivery. This includes infrastructure challenges, integration issues, organizational resistance, lack of clear ownership, compliance barriers, and user adoption problems.
      </div>
    </div>

    <!-- Question 7 -->
    <div class="question-card">
      <div class="question-header">
        <span class="question-number">Question 7</span>
        <span class="question-score">15 points</span>
      </div>
      <div class="question-text">Which monitoring approach is most effective for detecting model concept drift?</div>
      <div class="options-container">
        <div class="option" onclick="selectOption(7, 1, false)">
          <div class="option-marker">A</div>
          <div>Tracking input feature distributions only</div>
        </div>
        <div class="option" onclick="selectOption(7, 2, true)">
          <div class="option-marker">B</div>
          <div>Monitoring model performance metrics on recent labeled data</div>
        </div>
        <div class="option" onclick="selectOption(7, 3, false)">
          <div class="option-marker">C</div>
          <div>Analyzing prediction confidence distributions</div>
        </div>
        <div class="option" onclick="selectOption(7, 4, false)">
          <div class="option-marker">D</div>
          <div>Measuring system latency and throughput</div>
        </div>
      </div>
      <div class="explanation" id="explanation-7">
        <div class="explanation-title">Explanation:</div>
        Concept drift occurs when the relationship between features and target changes. The most direct way to detect this is by monitoring model performance (accuracy, precision, recall) on recent labeled data. Input distribution monitoring detects data drift but may miss concept drift where distributions stay the same but relationships change.
      </div>
    </div>

    <!-- Question 8 -->
    <div class="question-card">
      <div class="question-header">
        <span class="question-number">Question 8</span>
        <span class="question-score">15 points</span>
      </div>
      <div class="question-text">In ML governance, which principle is most important for ensuring algorithmic fairness?</div>
      <div class="options-container">
        <div class="option" onclick="selectOption(8, 1, false)">
          <div class="option-marker">A</div>
          <div>Using the largest possible training dataset</div>
        </div>
        <div class="option" onclick="selectOption(8, 2, false)">
          <div class="option-marker">B</div>
          <div>Maximizing overall model accuracy</div>
        </div>
        <div class="option" onclick="selectOption(8, 3, true)">
          <div class="option-marker">C</div>
          <div>Regularly testing for bias across protected demographic groups</div>
        </div>
        <div class="option" onclick="selectOption(8, 4, false)">
          <div class="option-marker">D</div>
          <div>Using only interpretable machine learning algorithms</div>
        </div>
      </div>
      <div class="explanation" id="explanation-8">
        <div class="explanation-title">Explanation:</div>
        Algorithmic fairness requires actively measuring and monitoring for bias across protected groups (race, gender, age, etc.). High overall accuracy can mask poor performance for minority groups. Regular bias testing, fairness metrics, and disparate impact analysis are essential governance practices.
      </div>
    </div>

    <div class="controls">
      <button class="btn btn-check" onclick="checkAnswers()" id="check-btn">Check All Answers</button>
      <button class="btn" onclick="resetQuiz()" id="reset-btn">Reset Quiz</button>
    </div>

    <div class="results-panel" id="results-panel">
      <div class="results-title">🎉 Quiz Complete!</div>
      <div class="final-score" id="final-score">0%</div>
      <div class="performance-message" id="performance-message"></div>
      <div id="badges-container"></div>
      <div style="margin-top: 20px;">
        <button class="btn" onclick="resetQuiz()">Retake Quiz</button>
      </div>
    </div>
  </div>
</div>

<script>
let answers = {};
let totalQuestions = 8;
let totalPoints = 100;

function selectOption(questionNum, optionNum, isCorrect) {
  // Clear previous selections for this question
  const questionCard = event.target.closest('.question-card');
  questionCard.querySelectorAll('.option').forEach(opt => {
    opt.classList.remove('selected');
  });

  // Mark the selected option
  event.target.closest('.option').classList.add('selected');

  // Store the answer
  answers[questionNum] = {
    selected: optionNum,
    correct: isCorrect,
    points: getQuestionPoints(questionNum)
  };

  updateProgress();
}

function getQuestionPoints(questionNum) {
  const pointsMap = {1: 10, 2: 10, 3: 10, 4: 10, 5: 15, 6: 15, 7: 15, 8: 15};
  return pointsMap[questionNum] || 10;
}

function updateProgress() {
  const answeredCount = Object.keys(answers).length;
  const correctCount = Object.values(answers).filter(a => a.correct).length;
  const earnedPoints = Object.values(answers).filter(a => a.correct).reduce((sum, a) => sum + a.points, 0);
  const scorePercent = totalPoints > 0 ? Math.round((earnedPoints / totalPoints) * 100) : 0;

  document.getElementById('answered-count').textContent = answeredCount;
  document.getElementById('correct-count').textContent = correctCount;
  document.getElementById('score-percent').textContent = scorePercent + '%';

  const progressPercent = (answeredCount / totalQuestions) * 100;
  const progressFill = document.getElementById('progress-fill');
  progressFill.style.width = progressPercent + '%';
  progressFill.textContent = `${answeredCount} / ${totalQuestions}`;

  // Enable check button if all questions answered
  const checkBtn = document.getElementById('check-btn');
  checkBtn.disabled = answeredCount < totalQuestions;
}

function checkAnswers() {
  // Show all explanations and mark correct/incorrect answers
  for (let i = 1; i <= totalQuestions; i++) {
    const questionCard = document.querySelectorAll('.question-card')[i - 1];
    const options = questionCard.querySelectorAll('.option');
    const explanation = document.getElementById(`explanation-${i}`);

    options.forEach((option, index) => {
      const optionNum = index + 1;
      const answer = answers[i];

      if (answer && answer.selected === optionNum) {
        if (answer.correct) {
          option.classList.add('correct');
        } else {
          option.classList.add('incorrect');
        }
      }

      // Also mark the correct answer if it wasn't selected
      const isCorrectOption = option.onclick.toString().includes('true');
      if (isCorrectOption && (!answer || answer.selected !== optionNum)) {
        option.classList.add('correct');
      }
    });

    explanation.classList.add('show');
  }

  showResults();
}

function showResults() {
  const correctCount = Object.values(answers).filter(a => a.correct).length;
  const earnedPoints = Object.values(answers).filter(a => a.correct).reduce((sum, a) => sum + a.points, 0);
  const scorePercent = Math.round((earnedPoints / totalPoints) * 100);

  document.getElementById('final-score').textContent = scorePercent + '%';

  let message = '';
  let badges = '';

  if (scorePercent >= 90) {
    message = 'Outstanding! You have excellent understanding of ML deployment and governance concepts.';
    badges += '<span class="badge excellent">Expert Level</span>';
    badges += '<span class="badge excellent">Deployment Master</span>';
  } else if (scorePercent >= 80) {
    message = 'Great job! You have solid understanding with room for minor improvements.';
    badges += '<span class="badge good">Advanced</span>';
    badges += '<span class="badge good">Well Prepared</span>';
  } else if (scorePercent >= 70) {
    message = 'Good work! Review the areas you missed to strengthen your understanding.';
    badges += '<span class="badge">Competent</span>';
  } else {
    message = 'Keep studying! Review the course materials and retake the quiz to improve.';
    badges += '<span class="badge needs-improvement">Needs Practice</span>';
  }

  if (correctCount === totalQuestions) {
    badges += '<span class="badge excellent">Perfect Score!</span>';
  }

  document.getElementById('performance-message').textContent = message;
  document.getElementById('badges-container').innerHTML = badges;
  document.getElementById('results-panel').classList.add('show');
  document.getElementById('results-panel').scrollIntoView({ behavior: 'smooth' });
}

function resetQuiz() {
  answers = {};

  // Reset all visual states
  document.querySelectorAll('.option').forEach(option => {
    option.classList.remove('selected', 'correct', 'incorrect');
  });

  document.querySelectorAll('.explanation').forEach(explanation => {
    explanation.classList.remove('show');
  });

  document.getElementById('results-panel').classList.remove('show');
  document.getElementById('check-btn').disabled = true;

  updateProgress();

  // Scroll to top
  window.scrollTo({ top: 0, behavior: 'smooth' });
}

// Initialize
updateProgress();

// Pop-out functionality
if (typeof window !== 'undefined' && window.self === window.top) {
  // Running standalone, hide the pop-out button
  document.addEventListener('DOMContentLoaded', function() {
    const popoutBtn = document.getElementById('popoutBtn');
    if (popoutBtn) {
      popoutBtn.style.display = 'none';
    }
  });
} else {
  // Running in iframe, show the pop-out button
  document.addEventListener('DOMContentLoaded', function() {
    const popoutBtn = document.getElementById('popoutBtn');
    if (popoutBtn) {
      popoutBtn.addEventListener('click', function() {
        window.open(window.location.href, '_blank');
      });
    }
  });
}
</script>

</body>
</html>